{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fO_-61sTBuyC"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.1.16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBi_7_8pLHAz"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46sfky37E70Z"
      },
      "outputs": [],
      "source": [
        "template1 = \"Genérame el código de una función en Python que realice lo siguiente: '{accion}'\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUCo-_TlNYI7"
      },
      "outputs": [],
      "source": [
        "prompt_template1 = PromptTemplate.from_template(template1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtbSBpY5OF5S"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-openai==0.1.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f3Lqt9ZD6Cx"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwYWCvRRBeel"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4KSVbRFCUOX"
      },
      "outputs": [],
      "source": [
        "llm1 = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8Lo5NbTOrDP"
      },
      "outputs": [],
      "source": [
        "chain1 = LLMChain(llm=llm1, prompt=prompt_template1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw5Zyn0DjHiD"
      },
      "outputs": [],
      "source": [
        "template2 = \"Dada una {función}, por verifica si se encuentra correctamente codificada, y explicame lo que hace\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mji2gBEYhR8D"
      },
      "outputs": [],
      "source": [
        "prompt_template2 = PromptTemplate.from_template(template2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAaX1mpqOXBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7af7e1fa-e150-4f7b-f1b2-f43cf6536afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/103.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain-groq==0.1.2 -Uq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBITX7fAe3oi"
      },
      "outputs": [],
      "source": [
        "groq_api_key = userdata.get('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWY66KSog5YJ"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvYSZbRughjI"
      },
      "outputs": [],
      "source": [
        "llm2 = ChatGroq(model=\"llama3-70b-8192\", temperature=0, api_key=groq_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmR-OrPHhAD_"
      },
      "outputs": [],
      "source": [
        "chain2 = LLMChain(llm=llm2, prompt=prompt_template2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71ukkIJ-klW-"
      },
      "outputs": [],
      "source": [
        "cadena_secuencial = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salida = cadena_secuencial.invoke(\"Calcula todos los números primos existentes hasta 100\")"
      ],
      "metadata": {
        "id": "zBjqbFlA-c6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(salida['output'])"
      ],
      "metadata": {
        "id": "FKmqV9ky-7vo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}